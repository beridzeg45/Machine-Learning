{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\berid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path=r'D:\\python data\\cv_flowers recognition\\flowers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories=[]\n",
    "for category in os.listdir(main_path):\n",
    "    if os.path.isdir(os.path.join(main_path,category)):\n",
    "        categories.append(category)\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 764/764 [00:01<00:00, 454.35it/s]\n",
      "100%|██████████| 1052/1052 [00:02<00:00, 453.14it/s]\n",
      "100%|██████████| 784/784 [00:01<00:00, 437.05it/s]\n",
      "100%|██████████| 733/733 [00:01<00:00, 399.90it/s]\n",
      "100%|██████████| 984/984 [00:02<00:00, 428.18it/s]\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for category in os.listdir(main_path):\n",
    "    for img in tqdm(os.listdir(os.path.join(main_path,category))):\n",
    "        img_path=os.path.join(main_path,category,img)\n",
    "        label=categories.index(category)\n",
    "        if img.split('.')[-1] not in ['jpeg','jpg','png','bmp']:\n",
    "            os.remove(img_path)\n",
    "            print(f'Removed {img}')\n",
    "        elif img is not None:\n",
    "            img_as_np=cv2.imread(img_path)\n",
    "            img_as_np=cv2.resize(img_as_np,(256,256))/255\n",
    "\n",
    "            X.append(img_as_np)\n",
    "            y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = list(zip(X, y))\n",
    "np.random.shuffle(combined)\n",
    "shuffled_data, shuffled_labels = zip(*combined)\n",
    "\n",
    "X = np.array(shuffled_data)\n",
    "y = np.array(shuffled_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 32\n",
    "X_batches = [X[i:i+batch_size] for i in range(0, len(X), batch_size)]\n",
    "\n",
    "last_batch_length = len(X_batches[-1])\n",
    "if last_batch_length < batch_size:\n",
    "    padding_shape = (batch_size - last_batch_length, 256,256,3)\n",
    "    X_batches[-1] = np.concatenate([X_batches[-1], np.zeros(padding_shape)], axis=0)\n",
    "\n",
    "# Convert the list of batches into a NumPy array\n",
    "X = np.array(X_batches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 32\n",
    "y_batches = [y[i:i+batch_size] for i in range(0, len(y), batch_size)]\n",
    "\n",
    "last_batch_length = len(y_batches[-1])\n",
    "if last_batch_length < batch_size:\n",
    "    padding_shape = (batch_size - last_batch_length,)\n",
    "    y_batches[-1] = np.concatenate([y_batches[-1], np.zeros(padding_shape)], axis=0)\n",
    "\n",
    "# Convert the list of batches into a NumPy array\n",
    "y = np.array(y_batches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#pickle.dump(X,open(os.path.join(os.path.dirname(main_path),'X.pickle'),'wb'))\n",
    "#pickle.dump(y,open(os.path.join(os.path.dirname(main_path),'y.pickle'),'wb'))\n",
    "\n",
    "X=pickle.load(open(os.path.join(os.path.dirname(main_path),'X.pickle'),'rb'))\n",
    "y=pickle.load(open(os.path.join(os.path.dirname(main_path),'y.pickle'),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4317, 256, 256, 3), (4317,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import random\n",
    "batch_x=X[0]\n",
    "batch_y=y[0]\n",
    "\n",
    "\n",
    "fig,axes=plt.subplots(4,5,figsize=(20,14))\n",
    "for i,index in enumerate(random.sample(range(len(batch_x)),20)):\n",
    "    ax=axes.flatten()[i]\n",
    "    ax.imshow(batch_x[index])\n",
    "    ax.set_title(categories[int(batch_y[index])],size=12)\n",
    "    ax.set_xticks([]), ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index=int(len(X)*0.8)\n",
    "val_index=int(len(X)*0.9)\n",
    "\n",
    "X_train, y_train=X[:train_index], y[:train_index]\n",
    "X_val, y_val=X[train_index:val_index], y[train_index:val_index]\n",
    "X_test, y_test=X[val_index:], y[val_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3453, 256, 256, 3),\n",
       " (432, 256, 256, 3),\n",
       " (432, 256, 256, 3),\n",
       " (3453,),\n",
       " (432,),\n",
       " (432,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_val.shape,X_test.shape, y_train.shape,y_val.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D,MaxPooling2D,MaxPooling3D,Flatten,Dense,Dropout\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\berid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\berid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\berid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 64)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 57600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               29491712  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29569925 (112.80 MB)\n",
      "Trainable params: 29569925 (112.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              #optimizer=Adam(learning_rate=0.001),  # Experiment with learning rate\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "logdir='D:\\python data\\cv_flowers recognition\\model\\logs'\n",
    "tensorboard_callbakcs=tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:From c:\\Users\\berid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\berid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      " 64/108 [================>.............] - ETA: 43s - loss: 1.5819 - accuracy: 0.3848"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train,y_train,epochs=15,validation_data=(X_val,y_val),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
